\chapter{Mathematical foundations}

\section{Notations, basic notions}

In this first section we want to define the elementary notions that are used
throughout the whole book. We use the usual notions
\[ \mathbb{N} = \{ 0, 1, 2, \ldots \}\ \mbox{for the natural numbers} \]
\[ \mathbb{Z} = \{ \ldots, -2, -1, 0, 1, 2, \ldots \}\ \mbox{for the integer
numbers} \]
\[ \mathbb{Q} = \{ \frac{a}{b} \mid a,b \in \mathbb{Z}, b \neq 0 \}\ \mbox{for
the rational numbers } \]

For the set operations we use $\cup$ for the union and $\cap$ for the
intersection. Also $A \subset B$, $a \in A$, $a \not\in A$, $\bar{A}$, $A - B$,
$A \times B$ and $\emptyset$ have their usual meaning. For the power set of a
set $A$ we write $2^A$ or $Pot(A)$. $Card(A)$ denotes the cardinality of $A$.
Logical implication is denoted by $\Rightarrow$.

{\bf Mappings} are denoted as $f : A \rightarrow B$, in that case $f$ is a
total mapping. We write $Q(f) = A, Z(f) = B$. Here $Q$ stands for ''Quelle'' (source)
and $Z$ for ''Ziel'' (target).

If $f: A \rightarrow B, g : B \rightarrow C$ are mappings, then $f \circ g : A
\rightarrow C$ is the composed mapping that one gets by applying $f$ first and
then $g$, i.e. $(f \circ g)(a) = g(f(a))$. If $f:A \rightarrow B$ and $C
\subset A$, then $f(C) = \{ f(c) \mid c \in C \}$.

A subset $R \subset A \times B$ is called a {\bf relation} between $A$ and $B$.
$R_f \subset A \times B$ with $R_f = \{ (a,b) \mid f(a) = b \}$ is the relation
{\bf induced by} mapping f or the {\bf graph} of $f$.

Let $f : A \rightarrow B$ be a mapping, $A_1 \subset A$ and $g : A_1 \rightarrow
B$ a mapping. $f$ is called the {\bf continuation} of $g$ if $f(a_1) = g(a_1),
a_1 \in A_1$. In this case we also write $f \mid _{A_1} = g$ (in words: $f$
restricted to $A_1$).

A {\bf semi-group} consists of a set $M$ an an associative operation on that
set, usually denoted as a multiplication. If a semi-group is commutative, we
also use ''$+$'' instead of ''$\cdot$''.

A semi-group is a {\bf monoid} if $M$ contains a neutral element. We often
denote it with $1_M$ or shortly $1$. In the commutative case we often write $0$
instead of $1$.

For $A,B \subset M$ we denote by $A \cdot B = \{ a b \mid a \in A, b \in B \}$
the {\bf complex product} of $A$ and $B$.

$A \subset M$ is a {\bf submonoid} of $M$ if the follwoing holds: $1_M \in A$
and $A$ is closed under the operation of $M$.

For an $A$, the set $A^*$ defined as follows, is the smallest submonoid of $M$
which contains $A$. More specific,
\[
		A^* = \bigcap_{M' \in M(A)} M'	
\]
where $M(A) = \{ M' \subset M \mid M'$ is a submonoid of $M, A \subset M' \}$.

It is easy to see that
\[
		A^* = \bigcup_{n \geq 0} A^n\ \mbox{with}\ A^0 = \{1\}\ \mbox{and}\ A^{n+1} =
		A^n \cdot A
\]

In the same sense the notion $A^+ = A^* - \{1\}$ is defined for semi-groups. $A$
is called the {\bf generation system} of $A^*$ and $A^+$ resp.

A special meaning for us is assigned to the set of ''words'' (string) over a
fixed alphabet $A$. We understand as words the finite sequences of elements from
the alphabet $A$ as for example $(a,b,d,a,c)$ for alphabet $A = \{ a,b,c,d \}$.

We define
\[
WORD(A) := \{\epsilon\} \cup A \cup (A \times A) \cup (A \times A \times A) \cup
\ldots
\]
as the set of words (strings) over $A$. The symbol $\epsilon$ denotes the {\bf
empty word} over $A$, that is $A^0 = \{\epsilon\}$.

If $w, v \in WORD(A)$ then $w \cdot v$ is the word over $A$ which you get by
concatenating $w$ and $v$, more formally:
\[
\mbox{If}\ w = (a_1,\ldots,a_k), v = (a_{k+1},\ldots,a_n)\ \mbox{then}\ w \cdot
v = (a_1, \ldots, a_n)
\]

With this operation $WORD(A)$ becomes a monoid which is usually also denoted
with $A^*$. This is slightly inconsistent because for the first definition of
the $*$-operator it holds $(A^*)^* = A^*$ but for the second usage of the
$*$-operator it holds $(A*)^* \neq A^*$.

The following example should clarify that: Let $A = \{a,b,c\}$ and let $(a,b,a)$
and $(b,a) \in A^*$.
\[(a,b,a)\cdot(b,a) = (a,b,a,b,a) \in A^*,\ \mbox{but}\]
\[((a,b,a),(b,a)) \in (A^*)^*\ \mbox{but}\ \notin A^*\].


Instead of $(a)$ we write just $a$. In this sense it holds $A \subset A^*$. This
also holds in the sense of the first definition of $A^*$.

If $w = (w_1,\ldots,w_n)$ we denote with $|a| = n$ the {\bf length} of $w$.
Obviously it holds: $|w \cdot v| = |w| + |v|$ and $|\epsilon| = 0$.

The {\bf mirror word} $w^R$ of a word $w = (w_1,\ldots,w_n)$ is the word
$(w_n,\ldots,w_1)$. $\epsilon^R = \epsilon$. It holds: $(w \cdot v)^R =
v^R \cdot w^R$.

In $A^*$ the reduction rules hold, i.e.
\begin{enumerate}
  \item $w \cdot x = w \cdot y \Rightarrow x = y$
  \item $x \cdot w = y \cdot w \Rightarrow x = y$
\end{enumerate}

We define {\bf left} and {\bf right quotient}:
\[ B^{-1} \cdot A = \{ v\ |\ \exists u \in B, w \in A : u \cdot v = w \} \]
and $A \cdot B^{-1}$ in the same way.

Because of the reduction rules it holds:
\[ \{w\}^{-1} \cdot \{v\}\ \mbox{and}\ \{w\}^{-1} \cdot \{v\}\ \mbox{resp. are
either empty or contain a single element.} \]

If $\{w\}^{-1} \cdot \{v\}$ is not empty we call $w$ a {\bf prefix} of $v$. If
$\{w\} \cdot \{v\}^{-1} \not= \emptyset $, we call $v$ a {\bf suffix} of $w$. In
the future we will always write just $w$ instead of $\{w\}$ and also $w$ is
prefix of $v$ if $w^{-1} \cdot v \not= \emptyset$.





\section{Monoid homomorphisms and congruence relations}

\begin{definition}
A {\bf monoid homomorphism} (short: homomorphism) from a monoid $M$ to a monoid
$S$ is a mapping $\Phi : M \to S$ with the following properties:
\begin{enumerate}
  \item $\Phi(m_1 \cdot m_2) = \Phi(m_1) \cdot \Phi(m_2), \quad m_1, m2 \in M$
  \item $\Phi(1_M) = 1_S$
\end{enumerate}
\end{definition}

It can be easily shown: if $M_1 \subset M$ is a submonoid of $M$, then
$\Phi(M_1)$ is a submonoid of $S$. If $S_1$ is a submonoid of $S$, then
$\Phi^{-1}(S_1)$ is a submonoid of $M$.

A homomorphism $\Phi : M \to S, \quad M,S$ monoids, is called
\begin{description}
  \item[monomorphism] if $\Phi$ is injective
  \item[epimorphism] if $\Phi$ is surjective
  \item[isomorphism] if $\Phi$ is bijective
\end{description}

Homomorphisms $\Phi : M \to M$ are called {\bf endomorphisms}, isomorphisms
$\Phi : M \to M$ are called {\bf automorphisms}.

Monoid $M$ and $S$ are called $isomorphic$, if there exists an isomorphism
between $M$ and $S$.

Of course, a monoid homomorphism cannot be defined arbitrarily on a monoid $M$.
Thus the following two questions arise:
\begin{enumerate}
  \item If $M_1 \subset M$ is a submonoid and $\Phi_1 : M_1 \to S$ is an arbitrary
mapping. When is it possible to extend $\Phi_1$ to a monoid homomorphism $\Phi
: M \to S$\ ?
	\item If $\Phi_1, \Phi_2$ both are monoid homomorphisms from $M$ to $S$ which
	coincide on $M_1 \subset M$. In which way can $\Phi_1$ and $\Phi_2$ be
	different? 
\end{enumerate}

The answer to this question of course depends on the structure of $M_1$. If
$M_1 = \{ 1_M \}$ then $\Phi$ is determined uniquely on $M_1$ but there is
little information on the relation between $\Phi_1$ and $\Phi2$.

The following two simple theorems which can be found in introductory algebra are
holding:
\begin{enumerate}
  \item If $M_1$ is a generating system of $M$ and $\Phi1, \Phi2 : M \to S$ both
  are monoid homomorphisms which coincide on $M_1$, then $\Phi1 = \Phi_2$.
  \item If $A$ is a set and $M = A^*$, and $\Phi_1 : A \to S$ is an arbitrary
  mapping, then there exists exactly one continuation $\Phi$ from $\Phi_1$ which
  is a monoid homomorphism from $A^*$ to $S$.
\end{enumerate}

\begin{definition}
A subset $A \subset M$ is called a {\bf free generating system} of $M$, if each
mapping $\Phi_1 : A \to S$, where $S$ is an arbitrary monoid, can be continued
to a monoid homomorphims in a unique way.
\end{definition}

A monoid with a free generating system is called a {\bf free monoid}.

$A^*$ therefore is a free monoid and $A$ is a free generating system of $A^*$.

It holds also:
If $A$ is a free generating system of $M$ and $A^*$ is the monoid of words
(string) over $A$, then $A^*$ and $M$ are isomorphic.

A free monoid has at most one free generating system. From that we can see that
the length $|w|$ of a word $w \in A^*$ can be defined in a unique way for any
free monoid.

The length is an example for a monoid homomorphism $L : A^* \to \mathbb{N}$.

If $\Phi : M \to S$ is a monoid homomorphism, then the sets $\{ \Phi^{-1}(s) |
s \in S \} \subset Pot(M)$ is a monoid isomorphic to $\Phi(M)$.

We want to handle now the following question: Let $M$ be a monoid, $L \subset M$
be any subset of $M$. Does there exist a monoid $S$ and a homomorphism $\Phi :
M \to S$ with the following property: There exists an $s \in S$ with $L \subset
\Phi^{-1}(s)$?

Of course, there always exists such an $S$: Choose $S = \{1\}$ and $\Phi(M) =
\{1\}$.

Therefore we strengthen our task: Find $S$ and $\Phi$ such that $L \subset
\Phi^{-1}(S)$ and for each other homomorphism $\Psi$ with that property holds:
$L \subset \Psi^{-1}(S') \Rightarrow \Phi^{-1}(S) \subset \Psi^{-1}(S')$.

We want to describe $L$ as close as possible by a monoid homomorphism.

Such an $S$ and $\Phi$ exists for each $L \subset M$ (see Algebra text), it is
named $synt_M(L)$ an is constructed as follows:

\begin{definition}
Let $M$ be a monoid and $L \subset M$. For $a, b \in M$ we define
\[ a \equiv b (L) \Leftrightarrow \mbox{For all}\ u, v \in M: u a v \in L
\Leftrightarrow u b v \in L
\]
\end{definition}

$\equiv (L)$ is a congruence relation, it holds:
\begin{enumerate}
  \item Let $[a]_L = \{ b \in M\ |\ a \equiv b (L) \}$\ then\ $b \in [a]_L
  \Rightarrow [a]_L = [b]_L $
  \item If we define $[a]_L \cdot [b]_L := [a b]_L$\ (complex product), then
  $synt_M(L) = \{ [a]_L\ |\ a \in M$ becomes a monoid and the mapping $\Psi_L :
  M \to synt_M(L)$\ with $\Psi_L(a) = [a]_L$\ is a monoidepimorphism.
\end{enumerate}

We call $\equiv (L)$ the {\bf syntactic congruence} of $L$ and $synt_M(L)$ the
{\bf syntactic monoid} of $L$ wrt. $M$.

To motivate the name $synt_M(L)$ we give an example from German language. Let
$A$ be the alphabet of German and $L$ the set of sentences in German. One can
denote two words $w_1$ and $w_2$ as congruent if they can always be exchanged in
each german sentence. There exist words that cannot always be exchanged. In the
sentence ''Apfel ist eine Kernfrucht'' the word ''Apfel'' can be exchanged by
''Birne'' but this is not possible in the sentence ''Apfel schreibt sich A p f e
l''.

The difficulty is of semantic nature. If you don't consider semantic correctness
of sentences you get a classification of words wrt. their syntactic meaning.

The important notion of ''syntactic congruence'' has been introduced by M. P.
Sch√ºtzenberger in the context of coding problems.

\section{Special monoids and the free group}

We have just learned about the syntactic monoid as an example for a monoid.
Further information on the theory of syntactic monoids can be found in
\cite{Saaloma} and \cite{Perrot}.

Let's have a look at more special monoids which we will need again later. To do
so, we introduce the notion of {\bf generated congruence relation}.

Let $A$ be an alphabet and $R = \{ u_i = v_i \ |\ i = 1, \ldots, n,\ u_i, v_i \in A^* \}$\ a set of equations.

Then by the following conditions an congruence relation $\bar{R}$ is uniquely
determined:

\begin{enumerate}
  \item $\{ (u_i, v_i)\ |\ u_i = v_i \in R \} \subset \bar{R}$
  \item $\bar{R}$\ is a congruence relation
  \item $\bar{R} \subset R'$\ for all $R'$\ fulfilling conditions 1) and 2).
\end{enumerate}

$\bar{R}$ is called the {\bf congruence relation generated by} $R$ over $A^*$.

The factor monoid $A^*/\bar{R}$ is named also simply $A^*/R$.

It holds: Words $u, v \in A^*$ are congruent wrt. $\bar{R}$ (Notation: $u
\equiv v (\bar{R})$) iff there exists $n \in \mathbb{N}, u_i \in A^*$ such that
for $i = 1, \ldots, n$



















































